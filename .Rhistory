getwd()
BS in Statistics and Data Science, /t *Sep 2020 – Jun. 2024*
BS in Statistics and Data Science, \t *Sep 2020 – Jun. 2024*
knitr::opts_chunk$set(echo = TRUE)
library(caret) # For dummyVars
library(randomForest) # For randomForest model
library(rsample) # For initial_split
install.packages("rsample")
library(caret) # For dummyVars
library(randomForest) # For randomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and pre-processed
data$country <- as.factor(data$country)
knitr::opts_chunk$set(echo = TRUE)
datafull <- read.csv("/Users/gimdong-gyu/Desktop/datafest2018-Updated-April12.csv")
library(dplyr)
data <- datafull
dim(data)
# Remove  "date", "industry", "normTitle", "descriptionCharacterLength"
#         "Language"
data <- data[ ,-c(1,9,10,12)]
data <- data[ ,-13]
# Remove rows where numOfRatings is NA
data <- data %>% filter(!is.na(numReviews))
data <- data %>% filter(city != "")
data <- data %>% filter(normTitleCategory != "")
# data <- data %>% filter(estimatedSalaryUSD != "0")
dim(data)
usd_to_cad <- 1.25 # 1 USD = 1.25 CAD
usd_to_eur <- 0.85 # 1 USD = 0.85 EUR
convert_to_usd <- function(currency, salary) {
if (currency == "" || currency == "USD") {
return(salary)
} else if (currency == "CAD") {
return(salary / usd_to_cad)
} else if (currency == "EUR") {
return(salary / usd_to_eur)
} else {
return(NA)
}
}
convert_to_usd_country <- function(country, salary) {
if (country == "" || country == "US") {
return(salary)
} else if (country == "CA") {
return(salary / usd_to_cad)
} else if (country == "DE") {
return(salary / usd_to_eur)
} else {
return(NA)
}
}
data$estimatedSalaryUSD <- mapply(convert_to_usd_country, data$country, data$estimatedSalary)
data <- data[ , -c(11, 12)]
na_percent <- colSums(is.na(data) | data == "") / dim(data)[1]
format(round(na_percent, 2))
# We can remove the row with na in supervisingJob, licenseRequiredJob, educationRequirements.
# For experienceRequired, rplace na with 0
data <- data %>% filter(supervisingJob != "" | !is.na(supervisingJob))
data$experienceRequired <- ifelse(is.na(data$experienceRequired), 0, data$experienceRequired)
colSums(is.na(data) | data == "")
nrow(data)
# we have 5,400,000 rows
grouped_data <- data %>% group_by(jobId) %>% summarise(Count = n())
# unique jobIds
number_of_groups <- nrow(grouped_data)
print(number_of_groups)
# Only 199,417 data
data_combined <- data %>%
group_by(jobId) %>%
summarise(
companyId = first(companyId),
country = first(country),
stateProvince = first(stateProvince),
city = first(city),
avgOverallRating = first(avgOverallRating),
numReviews = first(numReviews),
normTitleCategory = first(normTitleCategory),
descriptionWordCount = first(descriptionWordCount),
experienceRequired = first(experienceRequired),
estimatedSalaryUSD = first(estimatedSalaryUSD),
supervisingJob = first(supervisingJob),
licenseRequiredJob = first(licenseRequiredJob),
educationRequirements = first(educationRequirements),
avgJobAgeDays = mean(jobAgeDays, na.rm = TRUE),
avgClicks = mean(clicks, na.rm = TRUE),
avgLocalClicks = mean(localClicks, na.rm = TRUE)
#totalJobAgeDays = sum(jobAgeDays, na.rm = TRUE),
#totalClicks = sum(clicks, na.rm = TRUE),
#totalLocalClicks = sum(localClicks, na.rm = TRUE)
) %>%
ungroup()
data <- data_combined
# Save the data as csv file
write.csv(data_combined, "140xp_final_data.csv", row.names = FALSE)
data <- read.csv("140xp_final_data.csv")
library(randomForest)
set.seed(100)
sample <- sample(nrow(data), 10000)
# Remove companyid, jobid
data_model <- data[sample, -c(1,2)]
# random forest model to predict avgOverallRating
rf_model <- randomForest(avgOverallRating ~ ., data = data_model)
# Plot the importance
importance(rf_model)
varImpPlot(rf_model)
library(caret) # For dummyVars
library(randomForest) # For randomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and pre-processed
data$country <- as.factor(data$country)
data$stateProvince <- as.factor(data$stateProvince)
data$city <- as.factor(data$city)
data$normTitleCategory <- as.factor(data$normTitleCategory)
data$educationRequirements <- as.factor(data$educationRequirements)
set.seed(100)
sample <- sample(nrow(data), 10000)
data_model <- data[sample, -c(1,2)]
# Create dummy variables
dummies <- dummyVars("~ .", data = data_model)
data_transformed <- data.frame(predict(dummies, newdata = data_model))
# Separate features and target variable
X <- data_transformed[, !(names(data_transformed) %in% 'avgOverallRating')]
y <- data_transformed$avgOverallRating
# Split the data into training and test sets
set.seed(100)
split <- initial_split(data_transformed, prop = 0.8)
# IMPORTANT: Split X and y based on the rows in training and testing sets
X_train <- X[training(split)$rowIndex, ]
y_train <- y[training(split)$rowIndex]
X_test <- X[testing(split)$rowIndex, ]
y_test <- y[testing(split)$rowIndex]
# Train the Random Forest model
rf_model <- randomForest(X_train, y_train, ntree = 100)
library(caret) # For dummyVars
library(randomForest) # For randomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and pre-processed
data$country <- as.factor(data$country)
data$stateProvince <- as.factor(data$stateProvince)
data$city <- as.factor(data$city)
data$normTitleCategory <- as.factor(data$normTitleCategory)
data$educationRequirements <- as.factor(data$educationRequirements)
set.seed(100)
sample <- sample(nrow(data), 10000)
data_model <- data[sample, -c(1,2)]
# Create dummy variables
dummies <- dummyVars("~ .", data = data_model)
data_transformed <- data.frame(predict(dummies, newdata = data_model))
# Separate features and target variable
X <- data_transformed[, !(names(data_transformed) %in% 'avgOverallRating')]
y <- data_transformed$avgOverallRating
# Split the data into training and test sets
set.seed(100)
split <- initial_split(data_transformed, prop = 0.8)
# IMPORTANT: Split X and y based on the rows in training and testing sets
X_train <- X[training(split)$rowIndex, ]
y_train <- y[training(split)$rowIndex]
X_test <- X[testing(split)$rowIndex, ]
y_test <- y[testing(split)$rowIndex]
# Train the Random Forest model
rf_model <- randomForest(X_train, y_train)
library(randomForest) # For the RandomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and only contains numeric data
set.seed(100)
sample <- sample(nrow(data), 10000)
data_numeric <- data[sample, -c(1,2)] # Assuming this data is numeric
# Split the numeric data into training and test sets
set.seed(100)
split <- initial_split(data_numeric, prop = 0.8)
data_train <- training(split)
data_test <- testing(split)
# Separate features and target variable for training data
X_train <- data_train[, !(names(data_train) %in% 'avgOverallRating')]
y_train <- data_train$avgOverallRating
# Separate features and target variable for test data
X_test <- data_test[, !(names(data_test) %in% 'avgOverallRating')]
y_test <- data_test$avgOverallRating
# Train the Random Forest model
rf_model <- randomForest(x = X_train, y = y_train, ntree = 100)
library(randomForest) # For the RandomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and only contains numeric data
set.seed(100)
sample <- sample(nrow(data), 10000)
data_numeric <- data[sample, -c(1,2)] # Assuming this data is numeric
# Split the numeric data into training and test sets
set.seed(100)
split <- initial_split(data_numeric, prop = 0.8)
data_train <- training(split)
data_test <- testing(split)
# Separate features and target variable for training data
X_train <- data_train[, !(names(data_train) %in% 'avgOverallRating')]
y_train <- data_train$avgOverallRating
# Separate features and target variable for test data
X_test <- data_test[, !(names(data_test) %in% 'avgOverallRating')]
y_test <- data_test$avgOverallRating
# Train the Random Forest model
rf_model <- randomForest(x = X_train, y = y_train)
View(data_train)
View(X_test)
View(X_train)
library(randomForest) # For the RandomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and only contains numeric data
set.seed(100)
sample <- sample(nrow(data), 10000)
data_numeric <- data[sample, -c(1,2)] # Assuming this data is numeric
# Split the numeric data into training and test sets
set.seed(100)
split <- initial_split(data_numeric, prop = 0.8)
data_train <- training(split)
data_test <- testing(split)
# Separate features and target variable for training data
X_train <- data_train[, !(names(data_train) %in% 'avgOverallRating')]
y_train <- data_train$avgOverallRating
# Separate features and target variable for test data
X_test <- data_test[, !(names(data_test) %in% 'avgOverallRating')]
y_test <- data_test$avgOverallRating
# Train the Random Forest model
rf_model <- randomForest(x = X_train, y = y_train)
View(X_train)
data <- read.csv("140xp_final_data.csv")
library(randomForest) # For the RandomForest model
library(rsample) # For initial_split
# Assuming `data` is already loaded and only contains numeric data
set.seed(100)
sample <- sample(nrow(data), 10000)
data_numeric <- data[sample, -c(1,2)] # Assuming this data is numeric
# Split the numeric data into training and test sets
set.seed(100)
split <- initial_split(data_numeric, prop = 0.8)
data_train <- training(split)
data_test <- testing(split)
# Separate features and target variable for training data
X_train <- data_train[, !(names(data_train) %in% 'avgOverallRating')]
y_train <- data_train$avgOverallRating
# Separate features and target variable for test data
X_test <- data_test[, !(names(data_test) %in% 'avgOverallRating')]
y_test <- data_test$avgOverallRating
# Train the Random Forest model
rf_model <- randomForest(x = X_train, y = y_train)
# Predict on the test data
y_pred <- predict(rf_model, X_test)
# Calculate the RMSE
rmse <- sqrt(mean((y_test - y_pred)^2))
print(rmse)
# Calculate MSE for the model with all predictors
mse_all <- mean((data_model$avgOverallRating - predict(rf_model, data_model)) ^ 2)
data_model$avgOverallRating
predict(rf_model, data_model)
